{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giorgiacecchi/musicgen-restoration/blob/main/Progetto_ml_ID2_Giorgia_Cecchi_2069895.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKCTVGkqPxLz"
      },
      "source": [
        "#🎧 **MusicGen Audio Restoration  with DSP: Reducing Noise,Preserving Musicality** : 🎹\n",
        "\n",
        "\n",
        "- **Obiettivo progetto** ⚡\n",
        "\n",
        "Il mio progetto ha come obiettivo la generazione di clip musicali con MusicGen a partire da prompt testuali, seguita dal miglioramento della qualità dell'audio tramite tecniche di audio restoration.\n",
        "Il focus è la pulizia sonora (riduzione dei fruscii presenti) mantenendo il timbro originale.\n",
        "\n",
        "\n",
        "- **Fasi iniziali progetto**\n",
        "\n",
        "Nella prima parte del progetto mi sono occupata di:\n",
        "\n",
        "- Installare le librerie necessarie per lavorare con modelli pre-addestrati.\n",
        "\n",
        "- Caricare MusicGen (facebook/musicgen-small) da Hugging Face e generare 5 clip da semplici prompt testuali.\n",
        "\n",
        "- Organizzare i file .wav (16 kHz) per le fasi di restauro e valutazione.\n",
        "- Utilizzare un insieme di metriche per va,utare sullo stesso piano tutti i metodi."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxkymCk5YeaF"
      },
      "source": [
        "**Installo i pacchetti** 📥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "i9Dplt0eYUsb"
      },
      "outputs": [],
      "source": [
        "!pip -q install noisereduce librosa soundfile pandas scipy pyloudnorm transformers accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y22qbBmJUGUh"
      },
      "source": [
        "**Importo le librerie necessarie e costanti** 📕"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "s2iPpcbCeWBS"
      },
      "outputs": [],
      "source": [
        "# librerie\n",
        "import os,glob,shutil,subprocess,random\n",
        "import numpy as np, pandas as pd\n",
        "import librosa , soundfile as sf , matplotlib.pyplot as plt\n",
        "from scipy.signal import butter,sosfiltfilt\n",
        "from IPython.display import Audio,display\n",
        "import noisereduce as nr\n",
        "from transformers import MusicgenForConditionalGeneration, AutoProcessor\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\",category=UserWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3o7BqvIb0Dq"
      },
      "source": [
        "**📥 Clonazione del repository GitHub del progetto e sincronizzazione dei file LFS**\n",
        "\n",
        "Per lavorare sempre sulle stesse tracce audio senza doverle rigenerare ogni volta, ho deciso di mantenere i file .wav direttamente nel mio repository GitHub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "oYl9Czq7NtY8"
      },
      "outputs": [],
      "source": [
        "#clono repo GitHub del progetto e sincronizza file LFS\n",
        "repo_user=\"giorgiacecchi\"\n",
        "repo_name=\"musicgen-restoration\"\n",
        "repo_dir=f\"/content/{repo_name}\"\n",
        "\n",
        "if not os.path.exists(\".git\"):\n",
        "  subprocess.run([\"git\",\"clone\",f\"https://github.com/{repo_user}/{repo_name}.git\"], check=True)\n",
        "  os.chdir(repo_name)\n",
        "  print(\"cd nel repo:\", os.getcwd())\n",
        "else:\n",
        "  if os.path.isdir(repo_dir):\n",
        "    os.chdir(repo_dir)\n",
        "    print(\"cd nel repo:\", os.getcwd())\n",
        "\n",
        "\n",
        "subprocess.run([\"git\",\"lfs\",\"install\"], check=False)\n",
        "subprocess.run([\"git\",\"lfs\",\"pull\"], check=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yUGIzwQ3aXhI"
      },
      "outputs": [],
      "source": [
        "# Bootstrap: assicura che i 5 file WAV del repo siano presenti\n",
        "raw_dir=\"outputs/raw\"\n",
        "os.makedirs(raw_dir, exist_ok=True)\n",
        "\n",
        "files=sorted(glob.glob(f\"{raw_dir}/track_*.wav\"))\n",
        "print(\"trovati\", len(files), \"wav in\", raw_dir)\n",
        "\n",
        "for fp in files:\n",
        "    info=sf.info(fp)\n",
        "    print(os.path.basename(fp), f\"{info.duration:.2f}s\", f\"{info.samplerate}Hz\")\n",
        "\n",
        "if len(files)!=5:\n",
        "  raise RuntimeError(\"Mancano i 5 WAV nel repo:senza di quelli non rigenero.Aggiungili prima al repo.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HILOxBtOUehY"
      },
      "source": [
        "**Caricamento del modello di MusicGen 🎹**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "urI9MPlFUTY4"
      },
      "outputs": [],
      "source": [
        "#Carico il modello MusicGen(small) e il relativo processo\n",
        "model=MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-small\")\n",
        "processor=AutoProcessor.from_pretrained(\"facebook/musicgen-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4uWkxxOUw1g"
      },
      "source": [
        "Selezione del tipo di device 📔"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KiL8HI_3U8ez"
      },
      "outputs": [],
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2UbNI7RVcJK"
      },
      "source": [
        "**🎼Ora proviamo a generare la musica da un prompt**\n",
        "Fornisco in input un prompt testuale e ottengo in output un file  .wav di musica generata dal modello MusicGen(small).\n",
        "\n",
        "Passi eseguiti:\n",
        "1. creo la cartella \"outputs/\";\n",
        "2. per ogni prompt:\n",
        "- preparo gli input\n",
        "- genero un suono di circa 10 sec\n",
        "- salvo il .wav n outputs/track_i.wav\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-6swaaTfj78"
      },
      "outputs": [],
      "source": [
        "# cartelle risultati + SR\n",
        "in_dir=\"outputs/raw\"\n",
        "out_base=\"outputs/processed\"\n",
        "met_dir=\"outputs/results\"\n",
        "sr=16000\n",
        "\n",
        "os.makedirs(out_base,exist_ok=True)\n",
        "os.makedirs(met_dir,exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hN5oEGs_fwP9"
      },
      "outputs": [],
      "source": [
        "freeze=True    # True=usa WAV già presenti; False=genera dai prompt\n",
        "regen=False    # True=rigenera anche se il file esiste\n",
        "sr_out=16000   # sample rate di output\n",
        "\n",
        "prompts=[\n",
        "    \"a relaxing lo-fi beat for studying\",\n",
        "    \"a classical piano piece in a romantic style\",\n",
        "    \"an upbeat jazz quartet with saxophone\",\n",
        "    \"a cinematic orchestral theme\",\n",
        "    \"ambient meditation music with soft pads\"\n",
        "    ]\n",
        "\n",
        "def set_seed(s):\n",
        "    random.seed(s)\n",
        "    np.random.seed(s)\n",
        "    torch.manual_seed(s)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(s)\n",
        "    torch.backends.cudnn.deterministic=True\n",
        "    torch.backends.cudnn.benchmark=False\n",
        "\n",
        "def to_mono(y):\n",
        "    if y.ndim==2:\n",
        "        return np.mean(y,axis=0)\n",
        "    return y\n",
        "\n",
        "def resample_to(y,sr_in,sr_out):\n",
        "    if sr_in==sr_out:\n",
        "        return y\n",
        "    return librosa.resample(y.astype(np.float32), orig_sr=sr_in, target_sr=sr_out)\n",
        "\n",
        "os.makedirs(raw_dir,exist_ok=True)\n",
        "\n",
        "sr_model=getattr(processor,\"sampling_rate\",32000)\n",
        "print(\"sr_model=\",sr_model,\"| sr_out=\",sr_out)\n",
        "\n",
        "if freeze:\n",
        "    print(\"freeze=True → uso i WAV già nel repo, nessuna rigenerazione.\")\n",
        "    for fp in sorted(glob.glob(f\"{raw_dir}/track_*.wav\")):\n",
        "        display(Audio(fp,rate=sr_out))\n",
        "else:\n",
        "    seed=1234\n",
        "    tokens=512\n",
        "    for i,prompt in enumerate(prompts,start=1):\n",
        "        path=f\"{raw_dir}/track_{i}.wav\"\n",
        "        print(f\"traccia {i} | {prompt}\")\n",
        "\n",
        "        if os.path.exists(path) and not regen:\n",
        "            print(\"esiste già, skip:\",path)\n",
        "            display(Audio(path,rate=sr_out))\n",
        "            print(\"-\"*50)\n",
        "            continue\n",
        "\n",
        "        inputs=processor(text=[prompt],return_tensors=\"pt\").to(device)\n",
        "        set_seed(seed+i)\n",
        "        gen=torch.Generator(device=device).manual_seed(seed+i)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            audio_values=model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=tokens,\n",
        "                do_sample=True,\n",
        "                generator=gen\n",
        "            )\n",
        "        wav=audio_values[0].detach().cpu().numpy()\n",
        "        wav=to_mono(wav)\n",
        "        wav=resample_to(wav,sr_in=sr_model,sr_out=sr_out)\n",
        "\n",
        "        peak=np.max(np.abs(wav))+1e-12\n",
        "        if peak>1.0:\n",
        "            wav=wav/peak\n",
        "\n",
        "        sf.write(path,wav.astype(np.float32),sr_out)\n",
        "        print(\"salvata:\",path)\n",
        "        display(Audio(path,rate=sr_out))\n",
        "        print(\"-\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzblxezAoTsA"
      },
      "source": [
        "**Metriche comuni** utilizzate per valutare il suono restaurato\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FK8co0y5bY89"
      },
      "outputs": [],
      "source": [
        "def hf_band_energy_db(y,sr,low=6000):\n",
        "    S=np.abs(librosa.stft(y,n_fft=2048,hop_length=512))**2\n",
        "    freqs=librosa.fft_frequencies(sr=sr,n_fft=2048)\n",
        "    val=S[freqs>=low].sum()+1e-12\n",
        "    return 10*np.log10(val)\n",
        "\n",
        "def hpss_ratio(y):\n",
        "    H,P=librosa.decompose.hpss(librosa.stft(y))\n",
        "    h=np.sum(np.abs(H)**2); p=np.sum(np.abs(P)**2)+1e-12\n",
        "    return float(h/p)\n",
        "\n",
        "def log_mel_distance(y_ref,y_proc,sr,n_mels=64):\n",
        "    def _mel(y_audio):\n",
        "        M=librosa.feature.melspectrogram(y=y_audio,sr=sr,n_mels=n_mels,n_fft=2048,hop_length=512,power=2.0)\n",
        "        return np.log(M+1e-9)\n",
        "    A=_mel(y_ref)\n",
        "    B=_mel(y_proc)\n",
        "    m=min(A.shape[1],B.shape[1])\n",
        "    return float(np.mean(np.abs(A[:,:m]-B[:,:m])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4X1GKC2ofM4"
      },
      "source": [
        "**Plot generico** che poi ho applicato ad ogni modello"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daMXTwcjocNP"
      },
      "outputs": [],
      "source": [
        "TH_LOGMEL = 0.20 #soglia per la Log-Mel distance\n",
        "def plot_metric(df,column,title,ylabel,hline=0.0):\n",
        "    values=df.set_index(\"track\")[column]\n",
        "    tracks=values.index\n",
        "    #Se la metrica è la Log-Mel distance → usa la soglia dedicata\n",
        "    if \"log_mel\" in column.lower():\n",
        "        hline = TH_LOGMEL\n",
        "        #verde se sotto la soglia (=buono), rosso se sopra (=alterazione\n",
        "        #timbrica)\n",
        "        colors = [\"#4CAF50\" if v < hline else \"#F44336\" for v in values]\n",
        "    else:\n",
        "        # default: verde se sopra la linea, rosso se sotto\n",
        "        colors = [\"#4CAF50\" if v >= hline else \"#F44336\" for v in values]\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    bars=plt.bar(tracks,values,color=colors)\n",
        "    plt.axhline(hline,color=\"black\",linestyle=\"--\",linewidth=1)\n",
        "\n",
        "    for bar,val in zip(bars,values):\n",
        "        y=val+(0.04*abs(values.max()) if val>=hline else -0.06*abs(values.max()))\n",
        "        va=\"bottom\" if val>=hline else \"top\"\n",
        "        plt.text(bar.get_x()+bar.get_width()/2,y,f\"{val:.3f}\",ha=\"center\",va=va,fontsize=9)\n",
        "\n",
        "    plt.title(title,fontsize=13,fontweight=\"bold\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.xlabel(\"Traccia\")\n",
        "    plt.grid(axis=\"y\",linestyle=\"--\",alpha=0.6)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twTSarlwoqJZ"
      },
      "source": [
        "**Runner comune**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d1sVH2wJbZP"
      },
      "outputs": [],
      "source": [
        "def applico_e_confronto(method_name,process_fn,preview_n=5,play_raw=True):\n",
        "    rows=[]\n",
        "    files=sorted(glob.glob(os.path.join(in_dir,\"*.wav\")))\n",
        "    assert files,\"nessun .wav trovato in in_dir\"\n",
        "\n",
        "    out_dir=os.path.join(out_base,method_name)\n",
        "    os.makedirs(out_dir,exist_ok=True)\n",
        "\n",
        "    for i,fp in enumerate(files,1):\n",
        "        name=os.path.splitext(os.path.basename(fp))[0]\n",
        "        y,_=librosa.load(fp,sr=sr,mono=True)\n",
        "\n",
        "        #prima\n",
        "        b_hfdb=hf_band_energy_db(y,sr,6000)\n",
        "        b_hpss=hpss_ratio(y)\n",
        "\n",
        "        yp=process_fn(y,sr)\n",
        "\n",
        "        #dopo\n",
        "        a_hfdb=hf_band_energy_db(yp,sr,6000)\n",
        "        a_hpss=hpss_ratio(yp)\n",
        "        lmd=log_mel_distance(y,yp,sr)\n",
        "\n",
        "        #delta\n",
        "        d_hfdb=a_hfdb-b_hfdb  #<0 meglio\n",
        "        d_hpss=a_hpss-b_hpss  #>=0 meglio\n",
        "\n",
        "        #Criteri (2 su 3 per OK)\n",
        "        ok_hf=d_hfdb<0.0\n",
        "        ok_hpss=d_hpss>=0.0\n",
        "        ok_lmd=lmd<=TH_LOGMEL\n",
        "\n",
        "        ok_count=int(ok_hf)+int(ok_hpss)+int(ok_lmd)\n",
        "        criteri_ok=f\"{ok_count}/3\"\n",
        "        verdict=\"OK\" if ok_count>=2 else \"NO\"\n",
        "\n",
        "        rows.append({\n",
        "            \"track\":name,\n",
        "            \"before_hf_band_db\":b_hfdb,\"after_hf_band_db\":a_hfdb,\"delta_hf_band_db\":d_hfdb,\n",
        "            \"before_hpss_ratio\":b_hpss,\"after_hpss_ratio\":a_hpss,\"delta_hpss_ratio\":d_hpss,\n",
        "            \"log_mel_distance\":lmd,\n",
        "            \"OK_HFband\":ok_hf,\"OK_HPSS\":ok_hpss,\"OK_LogMel\":ok_lmd,\n",
        "            \"OK_count\":ok_count,\"criteri_ok\":criteri_ok,\"Verdetto\":verdict\n",
        "        })\n",
        "\n",
        "        if i<=preview_n:\n",
        "            print(f\"\\n{name} — {method_name}\")\n",
        "            if play_raw:\n",
        "                print(\"RAW\"); display(Audio(y,rate=sr))\n",
        "            print(\"PROC\"); display(Audio(yp,rate=sr))\n",
        "\n",
        "        sf.write(os.path.join(out_dir,f\"{name}_{method_name}.wav\"),yp,sr)\n",
        "\n",
        "    df=pd.DataFrame(rows)\n",
        "\n",
        "    order=[\n",
        "        \"track\",\n",
        "        \"before_hf_band_db\",\"after_hf_band_db\",\"delta_hf_band_db\",\n",
        "        \"before_hpss_ratio\",\"after_hpss_ratio\",\"delta_hpss_ratio\",\n",
        "        \"log_mel_distance\",\n",
        "        \"OK_HFband\",\"OK_HPSS\",\"OK_LogMel\",\"OK_count\",\"criteri_ok\",\"Verdetto\"\n",
        "    ]\n",
        "    df=df[order]\n",
        "\n",
        "    num_cols=[\n",
        "        \"before_hf_band_db\",\"after_hf_band_db\",\"delta_hf_band_db\",\n",
        "        \"before_hpss_ratio\",\"after_hpss_ratio\",\"delta_hpss_ratio\",\n",
        "        \"log_mel_distance\"\n",
        "    ]\n",
        "    for c in num_cols:\n",
        "        df[c]=df[c].astype(float).round(3)\n",
        "\n",
        "    display(df)\n",
        "    passed=(df[\"Verdetto\"]==\"OK\").sum()\n",
        "    print(f\"\\nRIEPILOGO: tracce OK={passed}/{len(df)}\")\n",
        "    csv_path=os.path.join(met_dir,f\"results_{method_name}.csv\")\n",
        "    df.to_csv(csv_path,index=False)\n",
        "    print(\"Tabella salvata in:\",csv_path,\"| WAV in:\",out_dir)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO-6HBx8i6K3"
      },
      "source": [
        "#Scelta dei modelli 💠\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8FMvpeojB7R"
      },
      "source": [
        "#**Modello 1**:  \n",
        "\n",
        "**NoiseReduce (DSP su alte frequenze)**\n",
        "\n",
        "Questo modello agisce in modo mirato sulla banda alta (≥ 6 kHz), dove è più evidente il fruscio generato da MusicGen.  \n",
        "La strategia che ho seguito è composta da tre passaggi:\n",
        "\n",
        "1. **Filtro passa-alto** per isolare solo le frequenze superiori a 6 kHz.  \n",
        "2. **NoiseReduce stazionario** applicato esclusivamente su questa banda per attenuare l’hiss.  \n",
        "3. **Ricombinazione** della parte filtrata con il resto del segnale originale, così da preservare il corpo e il timbro musicale.\n",
        "\n",
        "In questo modo la riduzione del rumore risulta efficace e mirata, senza modificare la struttura armonica né il carattere complessivo del brano.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtvKAml8pVaA"
      },
      "outputs": [],
      "source": [
        "def highpass(y,sr,fc=6000,order=6):\n",
        "  #creo un filtro passa-alto e lo applico al segnale\n",
        "  sos=butter(order,fc/(sr/2),btype=\"highpass\",output=\"sos\")\n",
        "  return sosfiltfilt(sos,y)\n",
        "\n",
        "def denoise_nr_alte(y,sr):\n",
        "  #isolo solo alte frequenze\n",
        "  y_hi=highpass(y,sr,fc=6000,order=6)\n",
        "  #faccio denoising solo sulla banda alta\n",
        "  y_hi_dn=nr.reduce_noise(y=y_hi,sr=sr,stationary=True,prop_decrease=0.7,\n",
        "                            time_constant_s=1.0,freq_mask_smooth_hz=600)\n",
        "  #ricompongo originale e \"ristrutturato\"\n",
        "  y_out=y-y_hi+y_hi_dn\n",
        "  mx=np.max(np.abs(y_out))+1e-12\n",
        "\n",
        "  #anti-clip:impedisce al suono di diventare troppo forte o distorto\n",
        "  if mx>0.99:\n",
        "    y_out=0.99*y_out/mx\n",
        "  return y_out\n",
        "\n",
        "#tabella + grafici\n",
        "df_nr=applico_e_confronto(\"m1_nr_alte\",denoise_nr_alte,preview_n=5,play_raw=True)\n",
        "plot_metric(df_nr, \"delta_hf_band_db\", \"Modello 1 — Δ HF-band dB (dopo − prima)\", \"dB\", hline=0.0)\n",
        "plot_metric(df_nr, \"delta_hpss_ratio\", \"Modello 1 —Δ HPSS ratio(dopo − prima)\", \"Δ\", hline=0.0)\n",
        "plot_metric(df_nr, \"log_mel_distance\", \"Modello 1 — Log-Mel distance\", \"Δ\", hline=TH_LOGMEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o0r5WN3XXOg"
      },
      "source": [
        "#**Modello 2**:\n",
        "\n",
        "**High-Band Spectral Subtraction (HB-SS)⏸▶**\n",
        "\n",
        "Il secondo modello utilizza la sottrazione spettrale, ma limitata soltanto alla banda alta (≥ 6 kHz).\n",
        "L’idea è ridurre il rumore stazionario dove si concentra il fruscio, evitando di alterare le frequenze medio-basse che contengono le armoniche principali.\n",
        "\n",
        "I parametri chiave sono:\n",
        "\n",
        "α (oversubtraction) per aumentare la rimozione del rumore,\n",
        "\n",
        "β (spectral floor) per prevenire il musical noise (artefatti metallici)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def denoise_hbss_alte(\n",
        "    y,sr,\n",
        "    f_cut=6000,\n",
        "    n_fft=2048,\n",
        "    hop_length=512,\n",
        "    alpha=1.4,      #fattore di oversubtraction\n",
        "    beta=0.06,      # soglia minima  spettrale\n",
        "    noise_pct=0.20, # % frame più \"silenziosi\" per stimare N(k)\n",
        "    min_quiet_sec=0.5):\n",
        "\n",
        "    #trasformata di Fourier a breve termine (STFT)\n",
        "    S=librosa.stft(y, n_fft=n_fft, hop_length=hop_length, window='hann', center=True)\n",
        "    mag=np.abs(S)\n",
        "    phase=np.angle(S)\n",
        "\n",
        "    #seleziono la banda alta\n",
        "    freqs=librosa.fft_frequencies(sr=sr,n_fft=n_fft)\n",
        "    hi=freqs>=f_cut\n",
        "\n",
        "    #individuo i frame \"silenziosi\"\n",
        "    frame_rms=librosa.feature.rms(S=S).flatten()\n",
        "    T=mag.shape[1]\n",
        "    n_quiet=max(1,int(noise_pct*T))\n",
        "    quiet_idx=np.argsort(frame_rms)[:n_quiet]\n",
        "\n",
        "    #se i frame silenziosi non bastano, uso i primi min_quiet_sec secondi\n",
        "    fallback_frames=int(np.ceil(min_quiet_sec*sr/hop_length))\n",
        "    if fallback_frames>0:\n",
        "        quiet_idx=np.unique(np.concatenate([quiet_idx,np.arange(min(T,fallback_frames))]))\n",
        "\n",
        "    #mediana sui frame silenziosi\n",
        "    noise_profile=np.median(mag[:, quiet_idx], axis=1)\n",
        "\n",
        "    #applico la sottrazione spettrale solo in banda alta\n",
        "    mag_clean=mag.copy()\n",
        "    mag_clean[hi,:]=np.maximum(\n",
        "        mag[hi,:]-alpha*noise_profile[hi,np.newaxis],\n",
        "        beta*mag[hi,:]\n",
        "    )\n",
        "\n",
        "    #ricostruisco il segnale con fase originale\n",
        "    S_clean=mag_clean*np.exp(1j*phase)\n",
        "    y_clean=librosa.istft(S_clean,hop_length=hop_length,window='hann',length=len(y))\n",
        "\n",
        "    #anti-clip:impedisce al suono di diventare troppo forte o distorto\n",
        "    peak=np.max(np.abs(y_clean))+1e-12\n",
        "    if peak>0.99:\n",
        "        y_clean=0.99*y_clean/peak\n",
        "\n",
        "    return y_clean\n",
        "\n",
        "#tabella + grafici\n",
        "df_hbss = applico_e_confronto(\"m2_hbss_alte\", denoise_hbss_alte, preview_n=5, play_raw=True)\n",
        "plot_metric(df_hbss, \"delta_hf_band_db\",\"Modello 2 — Δ HF-band dB (dopo − prima)\", \"dB\", hline=0.0)\n",
        "plot_metric(df_hbss, \"delta_hpss_ratio\",\"Modello 2 — Δ HPSS ratio (dopo − prima)\", \"Δ\", hline=0.0)\n",
        "plot_metric(df_hbss, \"log_mel_distance\",\"Modello 2 — Log-Mel distance\", \"Δ\", hline=TH_LOGMEL)"
      ],
      "metadata": {
        "id": "YvrJJqSb6X2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1OatIYidSQi"
      },
      "source": [
        "#**Modello 3**:\n",
        "\n",
        "**MCRA + filtro HF “safe” ⏸▶**\n",
        "\n",
        "Questo modello interviene su tutto lo spettro, stimando dinamicamente il rumore con l’algoritmo MCRA (Minimum Controlled Recursive Averaging), che “impara” il livello di rumore osservando i momenti più silenziosi del segnale.\n",
        "\n",
        "È l’approccio più aggressivo: riesce a ridurre in modo marcato il fruscio, soprattutto alle alte frequenze, ma introduce un maggiore rischio di alterazioni timbriche rispetto agli altri modelli."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1mfCIJkP3lQ"
      },
      "outputs": [],
      "source": [
        "def denoise_mcra_hf(y_np,sr,n_fft=2048,hop=512,f_cut=6000,alpha_n=0.98,\n",
        "                    kappa=1.25,alpha_gain=1.20,g_floor=0.055,fullband_mix=0.25,\n",
        "                    hf_boost=1.015,smooth_att=0.90,smooth_rel=0.75):\n",
        "    eps=1e-10\n",
        "    y=np.asarray(y_np,dtype=np.float32)\n",
        "    #se l'audio ha due canali(stereo),lo trasformiamo in uno solo (mono)\n",
        "    if y.ndim==2:\n",
        "        if y.shape[0]<=8 and y.shape[0]<y.shape[1]:\n",
        "            y=y.mean(axis=0)\n",
        "        else:\n",
        "            y=y.mean(axis=1)\n",
        "    #ShortTimeFourierTrasform\n",
        "    s=librosa.stft(y,n_fft=n_fft,hop_length=hop,window=\"hann\",center=True)\n",
        "    mag=np.abs(s)+eps\n",
        "    phase=np.exp(1j*np.angle(s))\n",
        "    p=mag**2\n",
        "    f_bins,t_frames=mag.shape\n",
        "    #maschera per distinguere alte frequenze\n",
        "    freqs=librosa.fft_frequencies(sr=sr,n_fft=n_fft)\n",
        "    mask_hf=freqs>=f_cut\n",
        "    #inizializzo stime rumore\n",
        "    n_est=p[:,0:1].copy()\n",
        "    m_track=p[:,0:1].copy()\n",
        "\n",
        "    mag_clean=np.empty_like(mag)\n",
        "    g_prev=np.ones((f_bins,1),dtype=np.float32)\n",
        "\n",
        "    # limite di variazione del gain tra frame\n",
        "    dg_max_hf=0.10  # 10% alle alte frequenze\n",
        "    dg_max_lf=0.20  # 20% alle basse frequenze\n",
        "\n",
        "    #ciclo su ogni frame\n",
        "    for t in range(t_frames):\n",
        "        y_psd=p[:,t:t+1]\n",
        "\n",
        "        #stima del rumore secondo MCRA\n",
        "        n_est=alpha_n*n_est+(1.0-alpha_n)*y_psd\n",
        "        m_track=np.minimum(kappa*m_track,y_psd)\n",
        "        n_hat=np.maximum(n_est,m_track)\n",
        "        #guadagno di Wiener\n",
        "        snr=y_psd/(n_hat+eps)\n",
        "        g_cur=snr/(snr+alpha_gain)\n",
        "        g_cur=np.clip(g_cur,g_floor,1.0)\n",
        "\n",
        "        #smoothing attacco/rilascio\n",
        "        down=g_cur<g_prev\n",
        "        g_s=g_prev.copy()\n",
        "        g_s[down]=smooth_att*g_prev[down]+(1.0-smooth_att)*g_cur[down]\n",
        "        g_s[~down]=smooth_rel*g_prev[~down]+(1.0-smooth_rel)*g_cur[~down]\n",
        "\n",
        "        #limiti per High frequencies e Low frequencies\n",
        "        if np.any(mask_hf):\n",
        "            g_hf=g_s[mask_hf,:]\n",
        "            g_prev_hf=g_prev[mask_hf,:]\n",
        "            g_hf=np.clip(g_hf,g_prev_hf*(1.0-dg_max_hf),g_prev_hf*(1.0+dg_max_hf))\n",
        "            g_s[mask_hf,:]=g_hf\n",
        "        if np.any(~mask_hf):\n",
        "            g_lf=g_s[~mask_hf,:]\n",
        "            g_prev_lf=g_prev[~mask_hf,:]\n",
        "            g_lf=np.clip(g_lf,g_prev_lf*(1.0-dg_max_lf),g_prev_lf*(1.0+dg_max_lf))\n",
        "            g_s[~mask_hf,:]=g_lf\n",
        "\n",
        "        g_prev=g_s\n",
        "\n",
        "        #applico guadagno alle  High frequencies\n",
        "        g_apply=np.ones_like(g_s)\n",
        "        if np.any(mask_hf):\n",
        "            g_apply[mask_hf,:]=g_s[mask_hf,:]\n",
        "        if np.any(~mask_hf):\n",
        "            g_apply[~mask_hf,:]=1.0-(1.0-g_s[~mask_hf,:])*fullband_mix\n",
        "\n",
        "        mag_clean[:,t:t+1]=mag[:,t:t+1]*g_apply\n",
        "\n",
        "    if hf_boost!=1.0 and np.any(mask_hf):\n",
        "        mag_clean[mask_hf,:]=mag_clean[mask_hf,:]*hf_boost\n",
        "\n",
        "    #ricostruisco segnale\n",
        "    s_clean=mag_clean*phase\n",
        "    y_out=librosa.istft(s_clean,hop_length=hop,length=len(y))\n",
        "    peak=np.max(np.abs(y_out))+eps\n",
        "    #anti-clip\n",
        "    if peak>0.999:\n",
        "        y_out=y_out*(0.999/peak)\n",
        "    return y_out.astype(np.float32)\n",
        "\n",
        "#tabella + grafici\n",
        "df_m3 = applico_e_confronto(\"m3_mcra_hf\", denoise_mcra_hf, preview_n=5, play_raw=True)\n",
        "plot_metric(df_m3, \"delta_hf_band_db\",\"Modello 3 — Δ HF-band dB (dopo − prima)\", \"dB\", hline=0.0)\n",
        "plot_metric(df_m3, \"delta_hpss_ratio\",\"Modello 3 — Δ HPSS ratio (dopo − prima)\", \"Δ\", hline=0.0)\n",
        "plot_metric(df_m3, \"log_mel_distance\",\"Modello 3 — Log-Mel distance\", \"Δ\", hline=TH_LOGMEL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvqa1ZoVTerE"
      },
      "source": [
        "#**Grafico finale** 🕜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCyozSwoFtS-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "CSV_M1=\"outputs/results/results_m1_nr_alte.csv\"\n",
        "CSV_M2=\"outputs/results/results_m2_hbss_alte.csv\"\n",
        "CSV_M3=\"outputs/results/results_m3_mcra_hf.csv\"\n",
        "\n",
        "def load_df(path,model):\n",
        "    df=pd.read_csv(path)\n",
        "    df=df.rename(columns={c:c.strip() for c in df.columns})\n",
        "    df[\"model\"]=model\n",
        "    return df[[\"model\",\"track\",\"OK_HFband\",\"OK_HPSS\",\"OK_LogMel\",\"OK_count\",\"criteri_ok\"]]\n",
        "\n",
        "m1=load_df(CSV_M1,\"M1_NR\")\n",
        "m2=load_df(CSV_M2,\"M2_HBSS\")\n",
        "m3=load_df(CSV_M3,\"M3_MCRA\")\n",
        "all_df=pd.concat([m1,m2,m3],ignore_index=True)\n",
        "\n",
        "#score ufficiale=% tracce con 3/3 OK\n",
        "by=all_df.groupby(\"model\",as_index=True)\n",
        "score=(by.apply(lambda g:(g[\"OK_count\"]==3).mean()*100)).to_frame(\"score\")\n",
        "\n",
        "#breakdown per metrica=% tracce OK per ciascun criterio\n",
        "score[\"HF_ok%\"]=by[\"OK_HFband\"].mean()*100\n",
        "score[\"HPSS_ok%\"]=by[\"OK_HPSS\"].mean()*100\n",
        "score[\"LogMel_ok%\"]=by[\"OK_LogMel\"].mean()*100\n",
        "\n",
        "#ordino per score\n",
        "score=score.sort_values(\"score\")\n",
        "\n",
        "#grafico A: solo score (classifica)\n",
        "#La traccia conta solo se sono tutti True contemporaneamente.\n",
        "#(OK_HFband, OK_HPSS, OK_LogMel)\n",
        "#se anche un solo criterio è False per tutte le tracce (es.OK_LogMel sempre\n",
        "#False in M3), nessuna traccia raggiunge 3/3 quindi 0%\n",
        "plt.figure(figsize=(7.5,3.2))\n",
        "bars=plt.barh(score.index,score[\"score\"],height=0.6)\n",
        "for b,v in zip(bars,score[\"score\"]):\n",
        "    plt.text(b.get_width()+1,b.get_y()+b.get_height()/2,f\"{v:.1f}%\",va=\"center\",fontsize=11,fontweight=\"bold\")\n",
        "plt.title(\"Score ufficiale: % tracce con 3/3 criteri OK\")\n",
        "plt.xlabel(\"percentuale\")\n",
        "plt.xlim(0,100)\n",
        "plt.grid(axis=\"x\",linestyle=\"--\",alpha=0.35)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "#grafico B: breakdown dei criteri\n",
        "cols=[\"HF_ok%\",\"HPSS_ok%\",\"LogMel_ok%\"]\n",
        "colors={\"HF_ok%\":\"royalblue\",\"HPSS_ok%\":\"seagreen\",\"LogMel_ok%\":\"darkorange\"}\n",
        "plt.figure(figsize=(9,4))\n",
        "left=[0]*len(score)\n",
        "for c in cols:\n",
        "    vals=score[c].values\n",
        "    plt.barh(score.index,vals,left=left,height=0.6,color=colors[c],edgecolor=\"white\")\n",
        "    left=[l+v for l,v in zip(left,vals)]\n",
        "handles=[Patch(facecolor=colors[c],label=c.replace(\"_ok%\",\"\").replace(\"_\",\" \")+ \" (OK%)\") for c in cols]\n",
        "plt.legend(handles=handles,loc=\"lower right\")\n",
        "plt.title(\"Affidabilità per criterio: % tracce OK\")\n",
        "plt.xlabel(\"percentuale\")\n",
        "plt.xlim(0,300)  # 3 criteri, max 300%\n",
        "plt.grid(axis=\"x\",linestyle=\"--\",alpha=0.35)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGkTzL6CzYeI"
      },
      "source": [
        "## Analisi finale e Conclusione\n",
        "\n",
        "Il **primo grafico** mostra la percentuale di tracce che superano **tutti e 3 i criteri** contemporaneamente:  \n",
        "- M1_NR raggiunge il 100% (tutte le tracce con 3/3 OK),  \n",
        "- M2_HBSS solo il 40% (tutti criteri rispettati solo in 2 tracce su 5 -> quindi 2/5=40%),  \n",
        "- M3_MCRA 0% (nessuna traccia rispetta tutti i criteri insieme, nessuno rispetta la log mel distance ).  \n",
        "\n",
        "Il **secondo grafico** scompone i criteri:\n",
        "si osserva che tutti i modelli riducono il fruscio (HF OK) e preservano le armoniche (HPSS OK), ma la **Log-Mel distance** è il vero punto critico:  \n",
        "- M1_NR resta sempre sotto soglia (100% OK),  \n",
        "- M2_HBSS solo nel 40% dei casi,  \n",
        "- M3_MCRA mai (0%).\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPgXUpgZsws2rGgcCAs2g3j",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}